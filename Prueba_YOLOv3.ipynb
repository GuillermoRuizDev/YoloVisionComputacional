{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prueba YOLOv3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOFJAeaeJtx6G32aH9EqbYI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guillermodxh/YoloVisionComputacional/blob/master/Prueba_YOLOv3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuggfr3GBBcm",
        "colab_type": "code",
        "outputId": "b2a27b78-907b-466c-8518-ab01a9d7a457",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "! git clone https://github.com/ArnavBalyan/Real-Time-Object-Detection_YOLO"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Real-Time-Object-Detection_YOLO' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAc2YJ3OFwpQ",
        "colab_type": "code",
        "outputId": "2d605e5a-58ca-4ab2-f568-eb5343ea3839",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "! wget \"https://pjreddie.com/media/files/yolov3.weights\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-07 12:23:18--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘yolov3.weights’\n",
            "\n",
            "yolov3.weights      100%[===================>] 236.52M   143KB/s    in 20m 44s \n",
            "\n",
            "2020-05-07 12:44:03 (195 KB/s) - ‘yolov3.weights’ saved [248007048/248007048]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-2aGx5qBVLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imutil import WebCamVideoStream"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_Svdaw5BP6p",
        "colab_type": "code",
        "outputId": "2b49e195-5c06-40c2-af1e-60e8f74e8340",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import cv2\n",
        "import argparse\n",
        "import numpy as np\n",
        "import time\n",
        "import urllib.request\n",
        "#from imutil import WebCamVideoStream\n",
        "from IPython.display import clear_output\n",
        "\n",
        "font = cv2.FONT_HERSHEY_PLAIN\n",
        "args_cfg = 'yolov3.cfg' \n",
        "args_wts = 'yolov3.weights'\n",
        "args_classes = 'yolov3.txt'\n",
        "\n",
        "def get_output_layers(net):\n",
        "    \n",
        "    layer_names = net.getLayerNames()\n",
        "    \n",
        "    output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "    return output_layers\n",
        "\n",
        "\n",
        "def draw_prediction(img, class_id, confidence, x, y, x_plus_w, y_plus_h):\n",
        "\n",
        "    label = str(classes[class_id])\n",
        "\n",
        "    color = COLORS[class_id]\n",
        "\n",
        "    cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 2)\n",
        "\n",
        "    cv2.putText(img, label, (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "#cap= WebCamVideoStream(src=0).start()\n",
        "#cap=cv2.VideoCapture(\"/Users/Arnav/downloads/harrypotterclip.mp4\")\n",
        "#cap=cv2.VideoCapture(\"/content/harrypotterclip.mp4\")\n",
        "\n",
        "#Colocar nombre de video aquí\n",
        "cap=cv2.VideoCapture(\"/content/mascotas_trailer2.mp4\")\n",
        "frame_id = 0\n",
        "starting_time= time.time()\n",
        "(h, w) = (0, 0)\n",
        "imgarr = []\n",
        "while True:\n",
        "    _,frame= cap.read() # \n",
        "    frame_id+=1\n",
        "    if frame is None:\n",
        "        print(\"Loop finished...BREAKING\")\n",
        "        break\n",
        "    clear_output()\n",
        "    print(frame_id)\n",
        "    Width = frame.shape[1]\n",
        "    Height = frame.shape[0]\n",
        "    scale = 0.00392\n",
        "\n",
        "    classes = None\n",
        "\n",
        "    with open(args_classes, 'r') as f:\n",
        "        classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "    COLORS = np.random.uniform(0, 255, size=(len(classes), 3))\n",
        "    net = cv2.dnn.readNet(args_wts, args_cfg)\n",
        "    blob = cv2.dnn.blobFromImage(frame, scale, (416,416), (0,0,0), True, crop=True)\n",
        "    net.setInput(blob)\n",
        "\n",
        "    outs = net.forward(get_output_layers(net))\n",
        "\n",
        "    class_ids = []\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "    conf_threshold = 0.5\n",
        "    nms_threshold = 0.4\n",
        "\n",
        "\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > 0.5:\n",
        "                center_x = int(detection[0] * Width)\n",
        "                center_y = int(detection[1] * Height)\n",
        "                w = int(detection[2] * Width)\n",
        "                h = int(detection[3] * Height)\n",
        "                x = center_x - w / 2\n",
        "                y = center_y - h / 2\n",
        "                class_ids.append(class_id)\n",
        "                confidences.append(float(confidence))\n",
        "                boxes.append([x, y, w, h])\n",
        "\n",
        "\n",
        "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
        "\n",
        "    for i in indices:\n",
        "        i = i[0]\n",
        "        box = boxes[i]\n",
        "        x = box[0]\n",
        "        y = box[1]\n",
        "        w = box[2]\n",
        "        h = box[3]\n",
        "        draw_prediction(frame, class_ids[i], confidences[i], round(x), round(y), round(x+w), round(y+h))\n",
        "    \n",
        "    elapsed_time = time.time() - starting_time\n",
        "    (h, w) = frame.shape[:2]\n",
        "    fps=frame_id/elapsed_time\n",
        "    cv2.putText(frame,\"FPS:\"+str(round(round(fps,2)+8)),(50,50),font,2,(0,0,0),1)\n",
        "    imgarr.append(frame)\n",
        "cap.release()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "Loop finished...BREAKING\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHfdSqz7BSGQ",
        "colab_type": "code",
        "outputId": "99db21c9-3391-4537-de92-ab0719c02a07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "print(h,w)\n",
        "out = cv2.VideoWriter('output.mp4',fourcc, 30.0,(w,h))\n",
        "for j in range (len(imgarr)):\n",
        "    clear_output()\n",
        "    out.write(imgarr[j])\n",
        "    print('Frames Processed:',j,'/',frame_id)\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frames Processed: 199 / 201\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}